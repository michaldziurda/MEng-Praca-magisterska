{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e48854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm, tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54eb5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa71c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_csv(r\"C:\\Users\\stezo\\Desktop\\Text_classification\\IMDB Dataset.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39707667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Usunięcie pustych rekordów.\n",
    "imdb_data['text'].dropna(inplace=True)\n",
    "\n",
    "# Zmiana wszystkich liter na małe.\n",
    "imdb_data['text'] = [entry.lower() for entry in imdb_data['text']]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "imdb_data['text']= [word_tokenize(entry) for entry in imdb_data['text']]\n",
    "\n",
    "# Usunięcie słów stopu, znaków niealfanumerycznych, lematyzacja tekstu.\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(imdb_data['text']):\n",
    "    Final_words = []\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    imdb_data.loc[index,'text_final'] = str(Final_words)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c216b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text ): \n",
    "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
    "    delete_dict[' '] = ' ' \n",
    "    table = str.maketrans(delete_dict)\n",
    "    text1 = str(text).translate(table)\n",
    "    #print('cleaned:'+text1)\n",
    "    textArr= text1.split()\n",
    "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n",
    "    \n",
    "    return text2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01add4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data['text'].dropna(axis = 0, how ='any',inplace=True) \n",
    "\n",
    "imdb_data['text'] = imdb_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe09bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one the other reviewers has mentioned that aft...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production the filming techni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought this was wonderful way spend time too ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family where little boy jake ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love the time money visually st...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought this movie did down right good job was...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>going have disagree with the previous comment ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects the star trek movies high art but ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      one the other reviewers has mentioned that aft...  positive\n",
       "1      wonderful little production the filming techni...  positive\n",
       "2      thought this was wonderful way spend time too ...  positive\n",
       "3      basically theres family where little boy jake ...  negative\n",
       "4      petter matteis love the time money visually st...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought this movie did down right good job was...  positive\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative\n",
       "49997  catholic taught parochial elementary schools n...  negative\n",
       "49998  going have disagree with the previous comment ...  negative\n",
       "49999  one expects the star trek movies high art but ...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "01096b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na zbiór trenningowy oraz testowy.\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(imdb_data['text'],\n",
    "                                                                    imdb_data['label'],\n",
    "                                                                    train_size=0.9,\n",
    "                                                                    test_size=0.1)\n",
    "\n",
    "# Kodowanie etykiety\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "\n",
    "# Wektoryzacja tekstu\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(imdb_data['text'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "03cd1ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 3057), ('the', 4405), ('other', 3086), ('reviewers', 3643), ('has', 2000)]\n"
     ]
    }
   ],
   "source": [
    "print(list(Tfidf_vect.vocabulary_.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1cae7410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set:  25000\n",
      "Size of the training set:  15000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the training set: \", Train_X_Tfidf.shape[0])\n",
    "print(\"Size of the training set: \", Test_X_Tfidf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ab9969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 243 ms\n",
      "Ridge Classifier Accuracy Score ->  0.8862\n"
     ]
    }
   ],
   "source": [
    "# Klasyfikator liniowy\n",
    "Linear = RidgeClassifier(alpha=1, \n",
    "                         fit_intercept=True, \n",
    "                         normalize='deprecated', \n",
    "                         copy_X=True, \n",
    "                         max_iter=None, \n",
    "                         tol=0.001, \n",
    "                         class_weight=None, \n",
    "                         solver='auto', \n",
    "                         random_state=None)\n",
    "\n",
    "%time Linear.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "predictions_Ridge = Linear.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"Ridge Classifier Accuracy Score -> \",accuracy_score(predictions_Ridge, Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4043649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.9 ms\n",
      "Naive Bayes Accuracy Score ->  0.8442\n"
     ]
    }
   ],
   "source": [
    "# Niwny klasyfikator Bayesowski\n",
    "Naive = naive_bayes.MultinomialNB(alpha=10, \n",
    "                                  fit_prior=True, \n",
    "                                  class_prior=None)\n",
    "\n",
    "%time Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1207f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 13s\n",
      "SVM Accuracy Score ->  0.8866\n"
     ]
    }
   ],
   "source": [
    "# Maszyna wektorów nośnych\n",
    "SVM = svm.SVC(C=0.5, \n",
    "              kernel='linear', \n",
    "              degree=3, \n",
    "              gamma='auto', \n",
    "              coef0=0.0, \n",
    "              shrinking=True, \n",
    "              probability=False, \n",
    "              tol=0.001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=False, \n",
    "              max_iter=- 1, \n",
    "              decision_function_shape='ovr', \n",
    "              break_ties=False, \n",
    "              random_state=None)\n",
    "\n",
    "%time SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7969f1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.81 s\n",
      "Decision Tree Accuracy Score ->  0.6734\n"
     ]
    }
   ],
   "source": [
    "# Drzewa decyzyjne\n",
    "Tree = tree.DecisionTreeClassifier(criterion='entropy', \n",
    "                                   splitter='best',\n",
    "                                   max_features='auto',\n",
    "                                   max_depth=None, \n",
    "                                   min_samples_split=2, \n",
    "                                   min_samples_leaf=1, \n",
    "                                   min_weight_fraction_leaf=0.0,  \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   class_weight=None, \n",
    "                                   ccp_alpha=0.0)\n",
    "\n",
    "%time Tree.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "predictions_Tree = Tree.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"Decision Tree Accuracy Score -> \",accuracy_score(predictions_Tree, Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e86d2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score ->  0.8526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Losowy Las\n",
    "Forest = RandomForestClassifier(n_estimators=1000,\n",
    "                                criterion='entropy',\n",
    "                                max_features='auto',\n",
    "                                n_jobs=-1,\n",
    "                                random_state=None,\n",
    "                                verbose=1)\n",
    "\n",
    "%time Forest.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "predictions_Forest = Forest.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"Random Forest Accuracy Score -> \",accuracy_score(predictions_Forest, Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844186c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
